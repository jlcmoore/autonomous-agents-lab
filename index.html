<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Autonomous Agents Lab </title> <meta name="author" content=" "> <meta name="description" content="We use our understanding of human learning to create artificial intelligence that learns more like people do. "> <meta name="keywords" content="reinforcement learning, computer vision, curiosity, interactive learning, multi-agent learning, optimal experiment design, active learning, cognitive models, childhood learning, learning differences, autism spectrum, learning technologies, assistive tech, augmented reality, mixed reality. "> <link rel="stylesheet" href="/AutonomousAgentsLab/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/AutonomousAgentsLab/assets/img/favicon.ico?dd386d03b0401db417fa328e8fb71a7e"> <link rel="stylesheet" href="/AutonomousAgentsLab/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://autonomousagentslab.github.io/AutonomousAgentsLab/"> <script src="/AutonomousAgentsLab/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/AutonomousAgentsLab/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/AutonomousAgentsLab/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/AutonomousAgentsLab/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/AutonomousAgentsLab/people/">people </a> </li> <li class="nav-item active"> <a class="nav-link" href="/AutonomousAgentsLab/_pages/values/">values </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Autonomous Agents Lab </h1> <p class="desc"></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/AutonomousAgentsLab/assets/img/meyer_green.avif" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/AutonomousAgentsLab/assets/img/meyer_green.avif?39a11be22db3f21ca32b300c52b57f15" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="meyer_green.avif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>520 Galvez Mall</p> <p>Stanford, CA 94305</p> <p><a href="https://ed.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford Graduate School of Education</a></p> <p><a href="https://cs.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford Computer Science</a></p> </div> </div> <div class="clearfix"> <p>We use our understanding of human learning to create artificial intelligence that learns more like people do. In turn, we use artificial intelligence and other technologies to model and assist human learning, and we apply the sorts of computational principles we work with in other areas that might benefit people. Because we have plenty of intuition on the settings in which learning thrives, we‚Äôll look to have fun, grow, and get enough sleep while we‚Äôre at it.</p> <p><strong>Keywords:</strong> reinforcement learning, computer vision, curiosity, interactive learning, multi-agent learning, optimal experiment design, active learning, cognitive models, childhood learning, learning differences, autism spectrum, learning technologies, assistive tech, augmented reality, mixed reality.</p> <p>Interested in our work? Interested in working with us?</p> <p><a href="mailto:nhaber%20at%20stanford%20dot%20edu">nhaber at stanford dot edu</a></p> </div> <h2> <a href="/AutonomousAgentsLab/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="haber_learning_2018" class="col-sm-8"> <div class="title">Learning to play with intrinsically-motivated, self-aware agents</div> <div class="author"> <a href="https://www.autonomousagents.stanford.edu/" rel="external nofollow noopener" target="_blank">Nick Haber</a>,¬†Damian Mrowca,¬†Stephanie Wang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Li F Fei-Fei, Daniel L Yamins' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Infants are experts at playing, with an amazing ability to generate novel structured behaviors in unstructured environments that lack clear extrinsic reward signals. We seek to mathematically formalize these abilities using a neural network that implements curiosity-driven intrinsic motivation. Using a simple but ecologically naturalistic simulated environment in which an agent can move and interact with objects it sees, we propose a" world-model" network that learns to predict the dynamic consequences of the agent‚Äôs actions. Simultaneously, we train a separate explicit" self-model" that allows the agent to track the error map of its world-model. It then uses the self-model to adversarially challenge the developing world-model. We demonstrate that this policy causes the agent to explore novel and informative interactions with its environment, leading to the generation of a spectrum of complex behaviors, including ego-motion prediction, object attention, and object gathering. Moreover, the world-model that the agent learns supports improved performance on object dynamics prediction, detection, localization and recognition tasks. Taken together, our results are initial steps toward creating flexible autonomous agents that self-supervise in realistic physical environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="zelikman_parsel_2023" class="col-sm-8"> <div class="title">Parselüêç: Algorithmic Reasoning with Language Models by Composing Decompositions</div> <div class="author"> Eric Zelikman,¬†Qian Huang,¬†Gabriel Poesia, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Noah Goodman, Nick Haber' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Despite recent success in large language model (LLM) reasoning, LLMs struggle with hierarchical multi-step reasoning tasks like generating complex programs. For these tasks, humans often start with a high-level algorithmic design and implement each part gradually. We introduce Parsel, a framework enabling automatic implementation and validation of complex algorithms with code LLMs. With Parsel, we automatically decompose algorithmic tasks into hierarchical natural language function descriptions and then search over combinations of possible function implementations using tests. We show that Parsel can be used across domains requiring hierarchical reasoning, including program synthesis and robotic planning. We find that, using Parsel, LLMs solve more competition-level problems in the APPS dataset, resulting in pass rates over 75% higher than prior results from directly sampling AlphaCode and Codex, while often using a smaller sample budget. Moreover, with automatically generated tests, we find that Parsel can improve the state-of-the-art pass@ 1 performance on HumanEval from 67% to 85%. We also find that LLM-generated robotic plans using Parsel are more than twice as likely to be considered accurate than directly generated plans. Lastly, we explore how Parsel addresses LLM limitations and discuss how Parsel may be useful for human programmers. We release our code at https://github. com/ezelikman/parsel.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/AutonomousAgentsLab/assets/img/publication_preview/xiang_towards_2025-480.webp 480w,/AutonomousAgentsLab/assets/img/publication_preview/xiang_towards_2025-800.webp 800w,/AutonomousAgentsLab/assets/img/publication_preview/xiang_towards_2025-1400.webp 1400w," type="image/webp" sizes="200px"> <img src="/AutonomousAgentsLab/assets/img/publication_preview/xiang_towards_2025.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="xiang_towards_2025.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="xiang_towards_2025" class="col-sm-8"> <div class="title">Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though</div> <div class="author"> Violet Xiang,¬†Charlie Snell,¬†Kanishk Gandhi, and <span class="more-authors" title="click to view 11 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '11 more authors' ? 'Alon Albalak, Anikait Singh, Chase Blagden, Duy Phung, Rafael Rafailov, Nathan Lile, Dakota Mahan, Louis Castricato, Jan-Philipp Franken, Nick Haber, Chelsea Finn' : '11 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">11 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2501.04682</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=euNCoVYAAAAJ&amp;citation_for_view=euNCoVYAAAAJ:bFI3QPDXJZMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">xiang_towards_2025</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xiang, Violet and Snell, Charlie and Gandhi, Kanishk and Albalak, Alon and Singh, Anikait and Blagden, Chase and Phung, Duy and Rafailov, Rafael and Lile, Nathan and Mahan, Dakota and Castricato, Louis and Franken, Jan-Philipp and Haber, Nick and Finn, Chelsea}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2501.04682}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Though}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2501.04682}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%6E%68%61%62%65%72%20%61%74%20%73%74%61%6E%66%6F%72%64%20%64%6F%74%20%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://www.linkedin.com/in/nick-haber-90922b76" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://scholar.google.com/citations?user=euNCoVYAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://twitter.com/nickhaber" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 . <span><a href="https://ed.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford Graduate School of Education</a></span> <span> | </span> <span><a href="https://cs.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford Computer Science</a></span> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/AutonomousAgentsLab/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/AutonomousAgentsLab/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/AutonomousAgentsLab/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/AutonomousAgentsLab/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/AutonomousAgentsLab/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/AutonomousAgentsLab/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/AutonomousAgentsLab/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/AutonomousAgentsLab/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/AutonomousAgentsLab/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/AutonomousAgentsLab/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/AutonomousAgentsLab/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/AutonomousAgentsLab/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/AutonomousAgentsLab/assets/js/search-data.js"></script> <script src="/AutonomousAgentsLab/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>