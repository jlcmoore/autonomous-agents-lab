<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Engineering Interactive Learning in Artificial Systems | Autonomous Agents Lab </title> <meta name="author" content=" "> <meta name="description" content="We look to develop machines that learn through autonomous exploration of and interaction with their environments -- as humans learn. To do this, we use deep reinforcement learning and employ and develop techniques in curiosity, active learning, and self-supervised learning. In doing so, we hope to create artificial systems that can learn more autonomously, flexibly, and robustly, with less demand on data. "> <meta name="keywords" content="reinforcement learning, computer vision, curiosity, interactive learning, multi-agent learning, optimal experiment design, active learning, cognitive models, childhood learning, learning differences, autism spectrum, learning technologies, assistive tech, augmented reality, mixed reality. "> <link rel="stylesheet" href="/AutonomousAgentsLab/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/AutonomousAgentsLab/assets/img/favicon.ico?dd386d03b0401db417fa328e8fb71a7e"> <link rel="stylesheet" href="/AutonomousAgentsLab/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://autonomousagentslab.github.io/AutonomousAgentsLab/projects/engineering_learning/"> <script src="/AutonomousAgentsLab/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/AutonomousAgentsLab/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/AutonomousAgentsLab//"> Autonomous Agents Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/AutonomousAgentsLab/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/AutonomousAgentsLab/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/AutonomousAgentsLab/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/AutonomousAgentsLab/people/">people </a> </li> <li class="nav-item active"> <a class="nav-link" href="/AutonomousAgentsLab/_pages/values/">values </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Engineering Interactive Learning in Artificial Systems</h1> <p class="post-description">We look to develop machines that learn through autonomous exploration of and interaction with their environments -- as humans learn. To do this, we use deep reinforcement learning and employ and develop techniques in curiosity, active learning, and self-supervised learning. In doing so, we hope to create artificial systems that can learn more autonomously, flexibly, and robustly, with less demand on data. </p> </header> <article> <p>Most successful machine learning algorithms of today rely on either carefully curated, human-labeled datasets, or extremely large amounts of interactive experience with simple environments. This reliance has critical drawbacks: the expansive and careful human effort in curating the data is expensive, and models trained in this way struggle to generalize beyond the scope of the data. In short, current AI is data-hungry, and in particular, for large-scale, carefully-crafted human input. This creates challenges, not only of expense and scale, but also of ethics: the desire to collect more and better data conflicts with people’s desire for privacy.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/AutonomousAgentsLab/assets/img/human_learning/environment_reduced_size.avif" sizes="95vw"></source> <img src="/AutonomousAgentsLab/assets/img/human_learning/environment_reduced_size.avif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="A reduced sized environment" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <a class="citation" href="#kim_active_2020">(Kim et al., 2020)</a> </div> <p>People, on the other hand, learn by virtue of their agency: they interact with various environments, exploring and building complex mental models of their world so as to flexibly adapt to a wide variety of tasks. This loop of action and perception is inseparable from the human learning process, as they decide what to look at, how to manipulate objects, and what to say to others.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/AutonomousAgentsLab/assets/img/human_learning/sample_complex_latest.avif" sizes="95vw"></source> <img src="/AutonomousAgentsLab/assets/img/human_learning/sample_complex_latest.avif" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Various graphs depicting agent performance" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> <a class="citation" href="#kim_active_2020">(Kim et al., 2020)</a> </div> <p>Thus far, we have developed curious, self-supervised deep reinforcement learning agents that explore and learn to model 3D physical environments and other agents. In doing so, they gain predictive models and useful visual representations. In the long term, we would like to grow these learning algorithms into a variety of robust technologies:</p> <ul> <li> <p>Curious, exploring robots that autonomously adapt to new surroundings and perform a variety of tasks.</p> </li> <li> <p>Social AI that interacts with you and understand your beliefs &amp; understandings.</p> </li> <li> <p>AI that accesses, harnesses, and welds human knowledge.</p> </li> </ul> <p><a class="citation" href="#haber_learning_2018">(Haber et al., 2018)</a></p> <p><a class="citation" href="#mrowca_flexible_2018">(Mrowca et al., 2018)</a></p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kim_active_2020" class="col-sm-8"> <div class="title">Active world model learning with progress curiosity</div> <div class="author"> Kuno Kim, Megumi Sano, Julian De Freitas, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Nick Haber, Daniel Yamins' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em></em> 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>World models are self-supervised predictive models of how the world evolves. Humans learn world models by curiously exploring their environment, in the process acquiring compact abstractions of high bandwidth sensory inputs, the ability to plan across long temporal horizons, and an understanding of the behavioral patterns of other agents. In this work, we study how to design such a curiosity-driven Active World Model Learning (AWML) system. To do so, we construct a curious agent building world models while visually exploring a 3D physical environment rich with distillations of representative real-world agents. We propose an AWML system driven by -Progress: a scalable and effective learning progress-based curiosity signal and show that -Progress naturally gives rise to an exploration policy that directs attention to complex but learnable dynamics in a balanced manner, as a result overcoming the “white noise problem”. As a result, our -Progress-driven controller achieves significantly higher AWML performance than baseline controllers equipped with state-of-the-art exploration strategies such as Random Network Distillation and Model Disagreement.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2018</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="haber_learning_2018" class="col-sm-8"> <div class="title">Learning to play with intrinsically-motivated, self-aware agents</div> <div class="author"> <a href="https://www.autonomousagents.stanford.edu/" rel="external nofollow noopener" target="_blank">Nick Haber</a>, Damian Mrowca, Stephanie Wang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Li F Fei-Fei, Daniel L Yamins' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Infants are experts at playing, with an amazing ability to generate novel structured behaviors in unstructured environments that lack clear extrinsic reward signals. We seek to mathematically formalize these abilities using a neural network that implements curiosity-driven intrinsic motivation. Using a simple but ecologically naturalistic simulated environment in which an agent can move and interact with objects it sees, we propose a" world-model" network that learns to predict the dynamic consequences of the agent’s actions. Simultaneously, we train a separate explicit" self-model" that allows the agent to track the error map of its world-model. It then uses the self-model to adversarially challenge the developing world-model. We demonstrate that this policy causes the agent to explore novel and informative interactions with its environment, leading to the generation of a spectrum of complex behaviors, including ego-motion prediction, object attention, and object gathering. Moreover, the world-model that the agent learns supports improved performance on object dynamics prediction, detection, localization and recognition tasks. Taken together, our results are initial steps toward creating flexible autonomous agents that self-supervise in realistic physical environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mrowca_flexible_2018" class="col-sm-8"> <div class="title">Flexible neural representation for physics prediction</div> <div class="author"> Damian Mrowca, Chengxu Zhuang, Elias Wang, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Nick Haber, Li F Fei-Fei, Josh Tenenbaum, Daniel L Yamins' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems</em>, 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Humans have a remarkable capacity to understand the physical dynamics of objects in their environment, flexibly capturing complex structures and interactions at multiple levels of detail.</p> </div> </div> </div> </li> </ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 . <span><a href="https://ed.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford Graduate School of Education</a></span> <span> | </span> <span><a href="https://cs.stanford.edu/" rel="external nofollow noopener" target="_blank">Stanford Computer Science</a></span> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/AutonomousAgentsLab/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/AutonomousAgentsLab/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/AutonomousAgentsLab/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/AutonomousAgentsLab/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/AutonomousAgentsLab/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/AutonomousAgentsLab/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/AutonomousAgentsLab/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/AutonomousAgentsLab/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/AutonomousAgentsLab/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/AutonomousAgentsLab/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/AutonomousAgentsLab/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/AutonomousAgentsLab/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/AutonomousAgentsLab/assets/js/search-data.js"></script> <script src="/AutonomousAgentsLab/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>